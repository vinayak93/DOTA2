{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This notebook contains the LSTM model on top of CNN layer with word embeddings'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This notebook contains the LSTM model on top of CNN layer with word embeddings using Hero Types'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credits https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "#https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\n",
    "#https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import the necessary Libraries'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [2],\n",
       "       [2],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now we load the required data sets'''\n",
    "df = pd.read_csv(\"dataset_without_duplicates_Bans analysis _with_types.csv\")\n",
    "matrix1 =np.array(df.loc[:,['match_id','type1','type2','type3','type4']])\n",
    "df1 = pd.read_csv(\"hero_names.csv\")\n",
    "matrix2 =np.array(df1.loc[:,['hero_id', 'Strength','Agility','Intelligence']])\n",
    "\n",
    "\n",
    "\n",
    "def dataprep1(index):\n",
    "    my_input = matrix1[:,1:index]\n",
    "    my_output = matrix1[:,index]\n",
    "    train_x = my_input[:40000,:]\n",
    "    train_x = np.asarray(train_x).astype(np.float32)\n",
    "    #train_x = tf.convert_to_tensor(train_x)\n",
    "    train_y = my_output[:40000]\n",
    "    train_y = np.asarray(train_y).astype(np.float32)\n",
    "    #train_y = tf.convert_to_tensor(train_y)\n",
    "    test_x = my_input[40000:50000,:]\n",
    "    test_x = np.asarray(test_x).astype(np.float32)\n",
    "    test_y = my_output[40000:50000]\n",
    "    test_y = np.asarray(test_y).astype(np.float32)\n",
    "    train_y_cat = to_categorical(train_y)\n",
    "    #train_y_cat = tf.convert_to_tensor(train_y_cat)\n",
    "    test_y_cat = to_categorical(test_y)\n",
    "    #test_y_cat = tf.convert_to_tensor(test_y_cat)\n",
    "    return train_x,train_y_cat,test_x,test_y_cat\n",
    "#train_x,train_y_cat,test_x,test_y_cat = dataprep1(2)\n",
    "#train_x\n",
    "my_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defining the model with embeddings along with CNN and LSTM. I have used adam optimizer with categorical crossentropy as our model predicts multiple classes.'''\n",
    "numpy.random.seed(7)\n",
    "# create the model\n",
    "def my_model(input_length_val,pool_size_val):\n",
    "    embedding_vecor_length = 32\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(114, embedding_vecor_length, input_length=input_length_val))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size_val))\n",
    "    model.add(LSTM(100,return_sequences=True))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1, 32)             3648      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 32)             3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 100)            53200     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 140,756\n",
      "Trainable params: 140,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0343 - acc: 0.4844 - precision_1: 0.5463 - recall_1: 0.2342\n",
      "Epoch 2/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0213 - acc: 0.4850 - precision_1: 0.5472 - recall_1: 0.2460\n",
      "Epoch 3/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0213 - acc: 0.4852 - precision_1: 0.5485 - recall_1: 0.2486\n",
      "Epoch 4/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0208 - acc: 0.4848 - precision_1: 0.5511 - recall_1: 0.2488\n",
      "Epoch 5/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0206 - acc: 0.4865 - precision_1: 0.5498 - recall_1: 0.2587\n",
      "Epoch 6/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0208 - acc: 0.4858 - precision_1: 0.5498 - recall_1: 0.2618\n",
      "Epoch 7/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0205 - acc: 0.4863 - precision_1: 0.5500 - recall_1: 0.2627\n",
      "Epoch 8/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0200 - acc: 0.4866 - precision_1: 0.5499 - recall_1: 0.2571\n",
      "Epoch 9/15\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.0202 - acc: 0.4865 - precision_1: 0.5511 - recall_1: 0.2563\n",
      "Epoch 10/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0201 - acc: 0.4863 - precision_1: 0.5497 - recall_1: 0.2576\n",
      "Epoch 11/15\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.0201 - acc: 0.4865 - precision_1: 0.5500 - recall_1: 0.2627\n",
      "Epoch 12/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0199 - acc: 0.4865 - precision_1: 0.5500 - recall_1: 0.2627\n",
      "Epoch 13/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0200 - acc: 0.4865 - precision_1: 0.5494 - recall_1: 0.2640\n",
      "Epoch 14/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0199 - acc: 0.4865 - precision_1: 0.5500 - recall_1: 0.2627\n",
      "Epoch 15/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0199 - acc: 0.4865 - precision_1: 0.5500 - recall_1: 0.2627\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.0625 - acc: 0.4341 - precision_1: 0.4687 - recall_1: 0.2031\n",
      "loss is:  1.0625079870224\n",
      "Accuracy is:  0.4341000020503998\n",
      "Precision is:  0.46872836351394653\n",
      "Recall is:  0.20309999585151672\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2, 32)             3648      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 100)            53200     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 140,756\n",
      "Trainable params: 140,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0763 - acc: 0.4178 - precision_2: 0.5102 - recall_2: 0.0613\n",
      "Epoch 2/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0641 - acc: 0.4207 - precision_2: 0.5091 - recall_2: 0.0778\n",
      "Epoch 3/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0625 - acc: 0.4228 - precision_2: 0.5158 - recall_2: 0.0810\n",
      "Epoch 4/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0623 - acc: 0.4228 - precision_2: 0.5182 - recall_2: 0.0840\n",
      "Epoch 5/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0621 - acc: 0.4252 - precision_2: 0.5163 - recall_2: 0.0859\n",
      "Epoch 6/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0620 - acc: 0.4234 - precision_2: 0.5194 - recall_2: 0.0829\n",
      "Epoch 7/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0618 - acc: 0.4241 - precision_2: 0.5161 - recall_2: 0.0983\n",
      "Epoch 8/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0615 - acc: 0.4254 - precision_2: 0.5140 - recall_2: 0.1010\n",
      "Epoch 9/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0616 - acc: 0.4243 - precision_2: 0.5131 - recall_2: 0.0945\n",
      "Epoch 10/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0615 - acc: 0.4247 - precision_2: 0.5152 - recall_2: 0.1035\n",
      "Epoch 11/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0614 - acc: 0.4239 - precision_2: 0.5112 - recall_2: 0.0999\n",
      "Epoch 12/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0612 - acc: 0.4247 - precision_2: 0.5144 - recall_2: 0.0938\n",
      "Epoch 13/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0613 - acc: 0.4237 - precision_2: 0.5203 - recall_2: 0.1001\n",
      "Epoch 14/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0612 - acc: 0.4261 - precision_2: 0.5177 - recall_2: 0.1036\n",
      "Epoch 15/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0612 - acc: 0.4252 - precision_2: 0.5175 - recall_2: 0.1088\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0885 - acc: 0.3765 - precision_2: 0.3998 - recall_2: 0.0812\n",
      "loss is:  1.0885438919067383\n",
      "Accuracy is:  0.3765000104904175\n",
      "Precision is:  0.3998030424118042\n",
      "Recall is:  0.0812000036239624\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 3, 32)             3648      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 3, 32)             3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 1, 100)            53200     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 140,756\n",
      "Trainable params: 140,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0797 - acc: 0.4198 - precision_3: 0.5174 - recall_3: 0.0612\n",
      "Epoch 2/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0671 - acc: 0.4252 - precision_3: 0.5328 - recall_3: 0.0868\n",
      "Epoch 3/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0667 - acc: 0.4262 - precision_3: 0.5363 - recall_3: 0.0811\n",
      "Epoch 4/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0658 - acc: 0.4244 - precision_3: 0.5374 - recall_3: 0.0865\n",
      "Epoch 5/15\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.0649 - acc: 0.4252 - precision_3: 0.5346 - recall_3: 0.0882\n",
      "Epoch 6/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0649 - acc: 0.4243 - precision_3: 0.5349 - recall_3: 0.0884\n",
      "Epoch 7/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0649 - acc: 0.4252 - precision_3: 0.5423 - recall_3: 0.0880\n",
      "Epoch 8/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0644 - acc: 0.4255 - precision_3: 0.5401 - recall_3: 0.0928\n",
      "Epoch 9/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0643 - acc: 0.4258 - precision_3: 0.5344 - recall_3: 0.0866\n",
      "Epoch 10/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0640 - acc: 0.4252 - precision_3: 0.5377 - recall_3: 0.0908\n",
      "Epoch 11/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0642 - acc: 0.4271 - precision_3: 0.5392 - recall_3: 0.0878\n",
      "Epoch 12/15\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0641 - acc: 0.4256 - precision_3: 0.5361 - recall_3: 0.0904\n",
      "Epoch 13/15\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.0640 - acc: 0.4261 - precision_3: 0.5370 - recall_3: 0.0878\n",
      "Epoch 14/15\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.0639 - acc: 0.4261 - precision_3: 0.5366 - recall_3: 0.0854\n",
      "Epoch 15/15\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.0638 - acc: 0.4259 - precision_3: 0.5374 - recall_3: 0.0901\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0917 - acc: 0.3782 - precision_3: 0.4253 - recall_3: 0.0666\n",
      "loss is:  1.0916978120803833\n",
      "Accuracy is:  0.3781999945640564\n",
      "Precision is:  0.4252873659133911\n",
      "Recall is:  0.066600002348423\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,5):\n",
    "    train_x,train_y_cat,test_x,test_y_cat = dataprep1(i)\n",
    "    input_length_val = i-1\n",
    "    if i==3:    \n",
    "        pool_size_val = 2\n",
    "        batch_size_val = 32\n",
    "    elif i==4:\n",
    "        pool_size_val = 3\n",
    "        batch_size_val = 32\n",
    "    elif i==2:\n",
    "        pool_size_val = 1\n",
    "        batch_size_val = 32\n",
    "    \n",
    "    model = my_model(input_length_val,pool_size_val)\n",
    "    # fit the model\n",
    "    model.fit(train_x, train_y_cat, epochs=15, batch_size=batch_size_val)\n",
    "    \n",
    "\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, accuracy, precision, recall = model.evaluate(test_x, test_y_cat, verbose=1)\n",
    "    #res = model.predict(test_x)\n",
    "    #print(\"Res is:\",res)\n",
    "    print(\"loss is: \", loss)\n",
    "    print(\"Accuracy is: \",accuracy)\n",
    "    print(\"Precision is: \",precision)\n",
    "    print(\"Recall is: \",recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The cells below are to be ignored as they are testing cells only'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.fit(train_x, train_y_cat, epochs=10, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "##scores = model.evaluate(test_x, test_y_cat, verbose=1)\n",
    "##print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "#predict_classes(object, x, batch_size = NULL, verbose = 0, steps = NULL)\n",
    "#class_vals = model.predict_classes(test_x, test_y_cat,verbose=1)\n",
    "##print(scores)\n",
    "#res = model.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6302646e-11, 2.0412136e-02, 5.5758455e-03, ..., 8.3727943e-04,\n",
       "        5.6127925e-11, 1.7126616e-02],\n",
       "       [2.5977874e-08, 2.4595298e-02, 8.7316809e-03, ..., 3.7359309e-03,\n",
       "        4.0153285e-08, 1.0456971e-02],\n",
       "       [2.5422263e-11, 1.6976409e-02, 7.7993367e-03, ..., 1.7016078e-04,\n",
       "        2.9651653e-11, 6.8962099e-03],\n",
       "       ...,\n",
       "       [5.0971623e-11, 2.0336319e-02, 3.6610698e-03, ..., 4.0176904e-04,\n",
       "        6.3429768e-11, 1.1689910e-02],\n",
       "       [1.1040675e-10, 2.7636470e-02, 3.2927773e-03, ..., 5.5798527e-04,\n",
       "        1.2071649e-10, 3.1962667e-02],\n",
       "       [2.1676995e-11, 3.9491843e-02, 4.2277668e-03, ..., 4.8325117e-05,\n",
       "        1.9527213e-11, 4.7792410e-03]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ypred4 [85 73 30 ... 69 85  7]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ypred4 = np.argmax(res, axis=1)\n",
    "print(\"Ypred4\", ypred4)\n",
    "#total_predictions_correct_4 = sum(p == t for p, t in zip(test_y, ypred4))\n",
    "#total_predictions_correct_4 = sum(p == t for p, t in zip(test_y_cat, res))\n",
    "counter = 0 \n",
    "for i in range(test_y_cat.shape[0]):\n",
    "    if test_y_cat[i].all()==ypred4[i].all():\n",
    "        counter=counter+1\n",
    "#accuracy_4 = total_predictions_correct_4/test_y.shape[0]\n",
    "accuracy_4 = counter/test_y_cat.shape[0]\n",
    "print(accuracy_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.610165596008301, 0.1526000052690506]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0144"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_vals = np.argmax(model.predict(test_x), axis=-1)\n",
    "class_vals.shape\n",
    "#test_y.shape\n",
    "count=0\n",
    "for i in class_vals:\n",
    "    if (class_vals[i]==test_y[i]):\n",
    "        count=count+1\n",
    "my_acc = count/class_vals.shape[0]\n",
    "my_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
