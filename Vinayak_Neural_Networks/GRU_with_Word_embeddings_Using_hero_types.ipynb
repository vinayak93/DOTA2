{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This notebook contains the GRU model with word embeddings'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This notebook contains the GRU model with word embeddings'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credits https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "#https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\n",
    "#https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import the necessary Libraries'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now we load the required data sets'''\n",
    "df = pd.read_csv(\"dataset_without_duplicates_Bans analysis.csv\")\n",
    "matrix1 =np.array(df.loc[:,['match_id','1hero_id','2hero_id','3hero_id','4hero_id']])\n",
    "df1 = pd.read_csv(\"hero_names.csv\")\n",
    "matrix2 =np.array(df1.loc[:,['hero_id', 'Strength','Agility','Intelligence']])\n",
    "\n",
    "def dataprep1(index):\n",
    "    my_input = matrix1[:,1:index]\n",
    "    my_output = matrix1[:,index]\n",
    "    train_x = my_input[:40000,:]\n",
    "    train_x = np.asarray(train_x).astype(np.float32)\n",
    "    #train_x = tf.convert_to_tensor(train_x)\n",
    "    train_y = my_output[:40000]\n",
    "    train_y = np.asarray(train_y).astype(np.float32)\n",
    "    #train_y = tf.convert_to_tensor(train_y)\n",
    "    test_x = my_input[40000:50000,:]\n",
    "    test_x = np.asarray(test_x).astype(np.float32)\n",
    "    test_y = my_output[40000:50000]\n",
    "    test_y = np.asarray(test_y).astype(np.float32)\n",
    "    train_y_cat = to_categorical(train_y)\n",
    "    #train_y_cat = tf.convert_to_tensor(train_y_cat)\n",
    "    test_y_cat = to_categorical(test_y)\n",
    "    #test_y_cat = tf.convert_to_tensor(test_y_cat)\n",
    "    return train_x,train_y_cat,test_x,test_y_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defining the model with embeddings along with CNN and LSTM. I have used adam optimizer with categorical crossentropy as our model predicts multiple classes.'''\n",
    "numpy.random.seed(7)\n",
    "# create the model\n",
    "def my_model(input_length_val,pool_size_val):\n",
    "    embedding_vecor_length = 32\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(114, embedding_vecor_length, input_length=input_length_val))\n",
    "    #model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    #model.add(MaxPooling1D(pool_size=pool_size_val))\n",
    "    model.add(GRU(100,return_sequences=True,unroll=True))\n",
    "    model.add(GRU(100,return_sequences=True))\n",
    "    model.add(GRU(100,return_sequences=True))\n",
    "    model.add(GRU(100))\n",
    "    model.add(Dense(113, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1, 32)             3648      \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 1, 100)            40200     \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 1, 100)            60600     \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 1, 100)            60600     \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 113)               11413     \n",
      "=================================================================\n",
      "Total params: 237,061\n",
      "Trainable params: 237,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 3.4197 - acc: 0.1770 - precision_2: 0.5417 - recall_2: 3.2500e-04\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 3.2931 - acc: 0.2195 - precision_2: 0.2500 - recall_2: 2.5000e-05\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 3.2335 - acc: 0.2306 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 3.2138 - acc: 0.2340 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 3.2073 - acc: 0.2340 - precision_2: 0.4000 - recall_2: 2.0000e-04\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.3696 - acc: 0.1999 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "loss is:  3.3696019649505615\n",
      "Accuracy is:  0.19990000128746033\n",
      "Precision is:  0.0\n",
      "Recall is:  0.0\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2, 32)             3648      \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 2, 100)            40200     \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 2, 100)            60600     \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 2, 100)            60600     \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 113)               11413     \n",
      "=================================================================\n",
      "Total params: 237,061\n",
      "Trainable params: 237,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 3.7324 - acc: 0.1082 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 3.5648 - acc: 0.1515 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 3.5221 - acc: 0.1636 - precision_3: 0.4706 - recall_3: 2.0000e-04\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 3.4983 - acc: 0.1651 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 3.4860 - acc: 0.1669 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.6757 - acc: 0.1468 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00\n",
      "loss is:  3.6756532192230225\n",
      "Accuracy is:  0.1467999964952469\n",
      "Precision is:  0.0\n",
      "Recall is:  0.0\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 3, 32)             3648      \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 3, 100)            40200     \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (None, 3, 100)            60600     \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 3, 100)            60600     \n",
      "_________________________________________________________________\n",
      "gru_19 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 113)               11413     \n",
      "=================================================================\n",
      "Total params: 237,061\n",
      "Trainable params: 237,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 3.7522 - acc: 0.1059 - precision_4: 0.3978 - recall_4: 9.2500e-04\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 3.5845 - acc: 0.1575 - precision_4: 0.4509 - recall_4: 0.0031\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 3.5373 - acc: 0.1733 - precision_4: 0.5036 - recall_4: 0.0052\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 3.5017 - acc: 0.1804 - precision_4: 0.5230 - recall_4: 0.0065\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 3.4760 - acc: 0.1844 - precision_4: 0.5117 - recall_4: 0.0077\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.6865 - acc: 0.1495 - precision_4: 0.3500 - recall_4: 0.0014\n",
      "loss is:  3.6864700317382812\n",
      "Accuracy is:  0.14949999749660492\n",
      "Precision is:  0.3499999940395355\n",
      "Recall is:  0.00139999995008111\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,5):\n",
    "    train_x,train_y_cat,test_x,test_y_cat = dataprep1(i)\n",
    "    input_length_val = i-1\n",
    "    if i==3:    \n",
    "        pool_size_val = 2\n",
    "        batch_size_val = 64\n",
    "    elif i==4:\n",
    "        pool_size_val = 3\n",
    "        batch_size_val = 64\n",
    "    elif i==2:\n",
    "        pool_size_val = 1\n",
    "        batch_size_val = 64\n",
    "    \n",
    "    model = my_model(input_length_val,pool_size_val)\n",
    "    # fit the model\n",
    "    model.fit(train_x, train_y_cat, epochs=5, batch_size=batch_size_val)\n",
    "    \n",
    "\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, accuracy, precision, recall = model.evaluate(test_x, test_y_cat, verbose=1)\n",
    "    #res = model.predict(test_x)\n",
    "    #print(\"Res is:\",res)\n",
    "    print(\"loss is: \", loss)\n",
    "    print(\"Accuracy is: \",accuracy)\n",
    "    print(\"Precision is: \",precision)\n",
    "    print(\"Recall is: \",recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The cells below are to be ignored as they are testing cells only'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.fit(train_x, train_y_cat, epochs=10, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "##scores = model.evaluate(test_x, test_y_cat, verbose=1)\n",
    "##print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "#predict_classes(object, x, batch_size = NULL, verbose = 0, steps = NULL)\n",
    "#class_vals = model.predict_classes(test_x, test_y_cat,verbose=1)\n",
    "##print(scores)\n",
    "#res = model.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6302646e-11, 2.0412136e-02, 5.5758455e-03, ..., 8.3727943e-04,\n",
       "        5.6127925e-11, 1.7126616e-02],\n",
       "       [2.5977874e-08, 2.4595298e-02, 8.7316809e-03, ..., 3.7359309e-03,\n",
       "        4.0153285e-08, 1.0456971e-02],\n",
       "       [2.5422263e-11, 1.6976409e-02, 7.7993367e-03, ..., 1.7016078e-04,\n",
       "        2.9651653e-11, 6.8962099e-03],\n",
       "       ...,\n",
       "       [5.0971623e-11, 2.0336319e-02, 3.6610698e-03, ..., 4.0176904e-04,\n",
       "        6.3429768e-11, 1.1689910e-02],\n",
       "       [1.1040675e-10, 2.7636470e-02, 3.2927773e-03, ..., 5.5798527e-04,\n",
       "        1.2071649e-10, 3.1962667e-02],\n",
       "       [2.1676995e-11, 3.9491843e-02, 4.2277668e-03, ..., 4.8325117e-05,\n",
       "        1.9527213e-11, 4.7792410e-03]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ypred4 [85 73 30 ... 69 85  7]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ypred4 = np.argmax(res, axis=1)\n",
    "print(\"Ypred4\", ypred4)\n",
    "#total_predictions_correct_4 = sum(p == t for p, t in zip(test_y, ypred4))\n",
    "#total_predictions_correct_4 = sum(p == t for p, t in zip(test_y_cat, res))\n",
    "counter = 0 \n",
    "for i in range(test_y_cat.shape[0]):\n",
    "    if test_y_cat[i].all()==ypred4[i].all():\n",
    "        counter=counter+1\n",
    "#accuracy_4 = total_predictions_correct_4/test_y.shape[0]\n",
    "accuracy_4 = counter/test_y_cat.shape[0]\n",
    "print(accuracy_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.610165596008301, 0.1526000052690506]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0144"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_vals = np.argmax(model.predict(test_x), axis=-1)\n",
    "class_vals.shape\n",
    "#test_y.shape\n",
    "count=0\n",
    "for i in class_vals:\n",
    "    if (class_vals[i]==test_y[i]):\n",
    "        count=count+1\n",
    "my_acc = count/class_vals.shape[0]\n",
    "my_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
