{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This implementation is using just a CNN to gather predicitons on the bans using hero type data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This implementation is using just a CNN to gather predicitons on the bans using hero type data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importing necessary libraries, i know some of these are repeted but it does not affect the performance of jupyter notebook so why not.'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from itertools import chain\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import keras.utils\n",
    "\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "'''Import the necessary Libraries'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now we load the dataset in the following cells'''\n",
    "\n",
    "df = pd.read_csv(\"dataset_without_duplicates_Bans analysis _with_types.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(461040, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1 =np.array(df.loc[:,['match_id','type1','type2','type3','type4']])\n",
    "matrix1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1928898739,          1,          1,          1,          1],\n",
       "       [1928932285,          1,          1,          2,          2],\n",
       "       [1928903165,          1,          3,          3,          1],\n",
       "       ...,\n",
       "       [1829187140,          2,          1,          2,          3],\n",
       "       [1829220503,          2,          3,          3,          1],\n",
       "       [1829227757,          1,          1,          1,          1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>hero_id</th>\n",
       "      <th>localized_name</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Agility</th>\n",
       "      <th>Intelligence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>npc_dota_hero_antimage</td>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Mage</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>npc_dota_hero_axe</td>\n",
       "      <td>2</td>\n",
       "      <td>Axe</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>npc_dota_hero_bane</td>\n",
       "      <td>3</td>\n",
       "      <td>Bane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>npc_dota_hero_bloodseeker</td>\n",
       "      <td>4</td>\n",
       "      <td>Bloodseeker</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>npc_dota_hero_crystal_maiden</td>\n",
       "      <td>5</td>\n",
       "      <td>Crystal Maiden</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  hero_id  localized_name  Strength  Agility  \\\n",
       "0        npc_dota_hero_antimage        1       Anti-Mage         0        1   \n",
       "1             npc_dota_hero_axe        2             Axe         1        0   \n",
       "2            npc_dota_hero_bane        3            Bane         0        0   \n",
       "3     npc_dota_hero_bloodseeker        4     Bloodseeker         0        1   \n",
       "4  npc_dota_hero_crystal_maiden        5  Crystal Maiden         0        0   \n",
       "\n",
       "   Intelligence  \n",
       "0             0  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"hero_names.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2 =np.array(df1.loc[:,['hero_id', 'Strength','Agility','Intelligence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   0,   1,   0],\n",
       "       [  2,   1,   0,   0],\n",
       "       [  3,   0,   0,   1],\n",
       "       [  4,   0,   1,   0],\n",
       "       [  5,   0,   0,   1],\n",
       "       [  6,   0,   1,   0],\n",
       "       [  7,   1,   0,   0],\n",
       "       [  8,   0,   1,   0],\n",
       "       [  9,   0,   1,   0],\n",
       "       [ 10,   0,   1,   0],\n",
       "       [ 11,   0,   1,   0],\n",
       "       [ 12,   0,   1,   0],\n",
       "       [ 13,   0,   0,   1],\n",
       "       [ 14,   1,   0,   0],\n",
       "       [ 15,   0,   1,   0],\n",
       "       [ 16,   1,   0,   0],\n",
       "       [ 17,   0,   0,   1],\n",
       "       [ 18,   1,   0,   0],\n",
       "       [ 19,   1,   0,   0],\n",
       "       [ 20,   0,   1,   1],\n",
       "       [ 21,   0,   0,   1],\n",
       "       [ 22,   0,   0,   1],\n",
       "       [ 23,   1,   0,   0],\n",
       "       [ 24,   1,   1,   1],\n",
       "       [ 25,   0,   0,   1],\n",
       "       [ 26,   0,   0,   1],\n",
       "       [ 27,   0,   0,   1],\n",
       "       [ 28,   1,   0,   0],\n",
       "       [ 29,   1,   0,   0],\n",
       "       [ 30,   0,   0,   1],\n",
       "       [ 31,   0,   0,   1],\n",
       "       [ 32,   0,   1,   0],\n",
       "       [ 33,   0,   0,   1],\n",
       "       [ 34,   0,   0,   1],\n",
       "       [ 35,   0,   1,   0],\n",
       "       [ 36,   0,   0,   1],\n",
       "       [ 37,   0,   0,   1],\n",
       "       [ 38,   1,   0,   0],\n",
       "       [ 39,   0,   0,   1],\n",
       "       [ 40,   0,   1,   0],\n",
       "       [ 41,   0,   1,   0],\n",
       "       [ 42,   1,   0,   0],\n",
       "       [ 43,   0,   0,   1],\n",
       "       [ 44,   0,   1,   0],\n",
       "       [ 45,   0,   0,   1],\n",
       "       [ 46,   0,   1,   0],\n",
       "       [ 47,   0,   1,   0],\n",
       "       [ 48,   0,   1,   0],\n",
       "       [ 49,   1,   0,   0],\n",
       "       [ 50,   0,   0,   1],\n",
       "       [ 51,   1,   0,   0],\n",
       "       [ 52,   0,   0,   1],\n",
       "       [ 53,   0,   0,   1],\n",
       "       [ 54,   1,   0,   0],\n",
       "       [ 55,   0,   0,   1],\n",
       "       [ 56,   0,   1,   0],\n",
       "       [ 57,   0,   0,   1],\n",
       "       [ 58,   0,   0,   1],\n",
       "       [ 59,   1,   0,   0],\n",
       "       [ 60,   1,   0,   0],\n",
       "       [ 61,   0,   1,   0],\n",
       "       [ 62,   0,   1,   0],\n",
       "       [ 63,   0,   1,   0],\n",
       "       [ 64,   0,   0,   1],\n",
       "       [ 65,   0,   0,   1],\n",
       "       [ 66,   0,   0,   1],\n",
       "       [ 67,   0,   1,   0],\n",
       "       [ 68,   0,   0,   1],\n",
       "       [ 69,   1,   0,   0],\n",
       "       [ 70,   0,   1,   0],\n",
       "       [ 71,   1,   0,   0],\n",
       "       [ 72,   0,   1,   0],\n",
       "       [ 73,   1,   0,   0],\n",
       "       [ 74,   0,   0,   1],\n",
       "       [ 75,   0,   0,   1],\n",
       "       [ 76,   0,   0,   1],\n",
       "       [ 77,   1,   0,   0],\n",
       "       [ 78,   1,   0,   0],\n",
       "       [ 79,   0,   0,   1],\n",
       "       [ 80,   0,   1,   0],\n",
       "       [ 81,   1,   0,   0],\n",
       "       [ 82,   0,   1,   0],\n",
       "       [ 83,   1,   0,   0],\n",
       "       [ 84,   0,   0,   1],\n",
       "       [ 85,   1,   0,   0],\n",
       "       [ 86,   0,   0,   1],\n",
       "       [ 87,   0,   0,   1],\n",
       "       [ 88,   0,   1,   0],\n",
       "       [ 89,   0,   1,   0],\n",
       "       [ 90,   0,   0,   1],\n",
       "       [ 91,   1,   0,   0],\n",
       "       [ 92,   0,   0,   1],\n",
       "       [ 93,   0,   1,   0],\n",
       "       [ 94,   0,   1,   0],\n",
       "       [ 95,   0,   1,   0],\n",
       "       [ 96,   1,   0,   0],\n",
       "       [ 97,   1,   0,   0],\n",
       "       [ 98,   1,   0,   0],\n",
       "       [ 99,   1,   0,   0],\n",
       "       [100,   1,   0,   0],\n",
       "       [101,   0,   0,   1],\n",
       "       [102,   1,   0,   0],\n",
       "       [103,   1,   0,   0],\n",
       "       [104,   1,   0,   0],\n",
       "       [105,   0,   0,   1],\n",
       "       [106,   0,   1,   0],\n",
       "       [107,   1,   0,   0],\n",
       "       [108,   1,   0,   0],\n",
       "       [109,   0,   1,   0],\n",
       "       [110,   1,   0,   0],\n",
       "       [111,   0,   0,   1],\n",
       "       [112,   0,   0,   1],\n",
       "       [113,   0,   1,   0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1928898739,          1,          1,          1,          1],\n",
       "       [1928932285,          1,          1,          2,          2],\n",
       "       [1928903165,          1,          3,          3,          1],\n",
       "       ...,\n",
       "       [1829187140,          2,          1,          2,          3],\n",
       "       [1829220503,          2,          3,          3,          1],\n",
       "       [1829227757,          1,          1,          1,          1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This fucntion helps me split the data for sequential prediction task'''\n",
    "def my_split(index):\n",
    "    my_input = matrix1[:,1:index]\n",
    "    my_output = matrix1[:,index]\n",
    "    train_x = my_input[:40000,:]\n",
    "    train_y = my_output[:40000]\n",
    "    test_x = my_input[40000:50000,:]\n",
    "    test_y = my_output[40000:50000]\n",
    "    train_y = to_categorical(train_y)\n",
    "    test_y = to_categorical(test_y)\n",
    "    return my_input,my_output,train_x,train_y,test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Helper funcitons for evaluation'''\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def my_f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def my_recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def my_precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defining the model with Conv1D layer, max pooling, flatten and 2 dense layers. Optimizer used is adam with loss mse '''\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "def my_model(train_x,test_x,n_steps_val,pool_size_val,kernel_size_val):\n",
    "    n_steps = n_steps_val\n",
    "    n_features = 1 #This is the channels as in a image\n",
    "    print(\"Test_X shape : \", test_x.shape)\n",
    "    print(\"Test X : \",test_x)\n",
    "    train_x_to_conv = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n",
    "    test_x_to_conv = test_x.reshape((test_x.shape[0], test_x.shape[1], n_features))\n",
    "    #print(train_x_to_conv.shape)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_steps, n_features),padding = 'same',use_bias=True))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu',padding='same'))\n",
    "    #model.add(MaxPooling1D(pool_size=pool_size_val))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc',my_f1,my_recall,my_precision])\n",
    "    print(model.summary())\n",
    "    # fit model\n",
    "    return model,train_x_to_conv,test_x_to_conv, n_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_X shape :  (40000, 4)\n",
      "Test X :  [[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 1, 64)             12352     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 16,062\n",
      "Trainable params: 16,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0385 - acc: 0.4793 - my_f1: 0.2432 - my_recall: 0.1978 - my_precision: 0.3403\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0227 - acc: 0.4821 - my_f1: 0.3468 - my_recall: 0.2647 - my_precision: 0.5222\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0217 - acc: 0.4838 - my_f1: 0.3512 - my_recall: 0.2618 - my_precision: 0.5466\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 1s 973us/step - loss: 1.0212 - acc: 0.4852 - my_f1: 0.3406 - my_recall: 0.2535 - my_precision: 0.5320\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 1s 973us/step - loss: 1.0207 - acc: 0.4864 - my_f1: 0.3530 - my_recall: 0.2627 - my_precision: 0.5505\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 1s 991us/step - loss: 1.0204 - acc: 0.4865 - my_f1: 0.3523 - my_recall: 0.2627 - my_precision: 0.5488\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0202 - acc: 0.4865 - my_f1: 0.3529 - my_recall: 0.2627 - my_precision: 0.5507\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0202 - acc: 0.4865 - my_f1: 0.3531 - my_recall: 0.2627 - my_precision: 0.5511\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0200 - acc: 0.4865 - my_f1: 0.3529 - my_recall: 0.2627 - my_precision: 0.5500\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0199 - acc: 0.4865 - my_f1: 0.3529 - my_recall: 0.2627 - my_precision: 0.5508\n",
      "313/313 [==============================] - 0s 700us/step - loss: 1.0601 - acc: 0.4341 - my_f1: 0.2804 - my_recall: 0.2033 - my_precision: 0.4652\n",
      "Score is:  [1.0600675344467163, 0.4341000020503998, 0.2804017961025238, 0.20327475666999817, 0.4651682376861572]\n",
      "Test_X shape :  (40000, 4)\n",
      "Test X :  [[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 2, 64)             256       \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 2, 64)             12352     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 19,262\n",
      "Trainable params: 19,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0761 - acc: 0.4175 - my_f1: 0.0397 - my_recall: 0.0273 - my_precision: 0.0846\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0650 - acc: 0.4200 - my_f1: 0.1168 - my_recall: 0.0753 - my_precision: 0.2780\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0638 - acc: 0.4205 - my_f1: 0.1353 - my_recall: 0.0867 - my_precision: 0.3305\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0628 - acc: 0.4223 - my_f1: 0.1485 - my_recall: 0.0951 - my_precision: 0.3610\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0623 - acc: 0.4223 - my_f1: 0.1503 - my_recall: 0.0964 - my_precision: 0.3644\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0621 - acc: 0.4207 - my_f1: 0.1375 - my_recall: 0.0881 - my_precision: 0.3348\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0619 - acc: 0.4223 - my_f1: 0.1611 - my_recall: 0.1030 - my_precision: 0.3964\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0618 - acc: 0.4218 - my_f1: 0.1453 - my_recall: 0.0929 - my_precision: 0.3580\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0616 - acc: 0.4226 - my_f1: 0.1542 - my_recall: 0.0988 - my_precision: 0.3761\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.0615 - acc: 0.4235 - my_f1: 0.1664 - my_recall: 0.1066 - my_precision: 0.4040\n",
      "313/313 [==============================] - 0s 792us/step - loss: 1.0885 - acc: 0.3822 - my_f1: 0.1326 - my_recall: 0.0812 - my_precision: 0.4002\n",
      "Score is:  [1.088479995727539, 0.3822000026702881, 0.13256339728832245, 0.08117012679576874, 0.4001706540584564]\n",
      "Test_X shape :  (40000, 4)\n",
      "Test X :  [[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 3, 64)             256       \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 3, 64)             12352     \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                9650      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 22,462\n",
      "Trainable params: 22,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0805 - acc: 0.4211 - my_f1: 0.0465 - my_recall: 0.0305 - my_precision: 0.1450\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.0685 - acc: 0.4228 - my_f1: 0.1297 - my_recall: 0.0819 - my_precision: 0.3858\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.0663 - acc: 0.4251 - my_f1: 0.1504 - my_recall: 0.0929 - my_precision: 0.4799\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.0659 - acc: 0.4255 - my_f1: 0.1600 - my_recall: 0.0987 - my_precision: 0.5139\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.0651 - acc: 0.4265 - my_f1: 0.1421 - my_recall: 0.0857 - my_precision: 0.5043\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.0647 - acc: 0.4254 - my_f1: 0.1505 - my_recall: 0.0909 - my_precision: 0.5285\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.0646 - acc: 0.4275 - my_f1: 0.1498 - my_recall: 0.0904 - my_precision: 0.5207\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.0644 - acc: 0.4257 - my_f1: 0.1453 - my_recall: 0.0869 - my_precision: 0.5338\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.0642 - acc: 0.4265 - my_f1: 0.1483 - my_recall: 0.0886 - my_precision: 0.5357\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.0640 - acc: 0.4264 - my_f1: 0.1423 - my_recall: 0.0850 - my_precision: 0.5186\n",
      "  1/313 [..............................] - ETA: 0s - loss: 1.1519 - acc: 0.2812 - my_f1: 0.0000e+00 - my_recall: 0.0000e+00 - my_precision: 0.0000e+00WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "313/313 [==============================] - 0s 857us/step - loss: 1.0914 - acc: 0.3783 - my_f1: 0.0610 - my_recall: 0.0338 - my_precision: 0.3817\n",
      "Score is:  [1.091390609741211, 0.3783000111579895, 0.060987576842308044, 0.033845845609903336, 0.38167887926101685]\n"
     ]
    }
   ],
   "source": [
    "'''This code produces evaluations for all the hero bans'''\n",
    "for i in range(2,5):\n",
    "    if i==2:\n",
    "        n_steps_val = 1\n",
    "        pool_size_val = 1\n",
    "        kernel_size_val =1\n",
    "    elif i==3:\n",
    "        n_steps_val = 2\n",
    "        pool_size_val = 1\n",
    "        kernel_size_val = 2\n",
    "    else:\n",
    "        n_steps_val = 3\n",
    "        pool_size_val = 2\n",
    "        kernel_size_val  = 2\n",
    "    #print(\"I am herrr!!!!!\")\n",
    "    my_input,my_output,train_x,train_y,test_x,test_y = my_split(i)\n",
    "    ###K.clear_session() \n",
    "    model,train_x_to_conv,test_x_to_conv, n_features = my_model(train_x,train_y,n_steps_val,pool_size_val,kernel_size_val)\n",
    "    model.fit(train_x_to_conv, train_y, epochs=10, verbose=1)\n",
    "    # demonstrate prediction\n",
    "    #x_input = array([70, 80, 0])\n",
    "    x_input = test_x\n",
    "    x_input = x_input.reshape((x_input.shape[0], n_steps_val, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0,use_multiprocessing=True)\n",
    "    #####print(yhat)\n",
    "    # evaluate the model\n",
    "    #loss, accuracy, precision, recall = model.evaluate(test_x, test_y, verbose=1)\n",
    "    score = model.evaluate(x_input, test_y, verbose=1)\n",
    "    print(\"Score is: \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 11 75 ... 73 69 75]\n"
     ]
    }
   ],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credits : https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/\n",
    "#!pip install tensorflow\n",
    "#!pip install keras\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
